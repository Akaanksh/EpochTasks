{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive"
      ],
      "metadata": {
        "id": "CD9KlUMQx_h-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stuLMUY64t_z",
        "outputId": "9d9c85f0-eeda-40ed-a360-d39d6e14414d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "audio_folder = \"/content/drive/MyDrive/multimodal_emotion_recognition/data\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create MFCC Dataset"
      ],
      "metadata": {
        "id": "96P0hdSmyC_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MFCCDataset(Dataset):\n",
        "    def __init__(self, mfcc_dir):\n",
        "        self.mfcc_dir = mfcc_dir\n",
        "        self.files = [f for f in os.listdir(mfcc_dir) if f.endswith('.npy')]\n",
        "        self.label_map = {\n",
        "            'neutral': 0,\n",
        "            'calm': 1,\n",
        "            'happy': 2,\n",
        "            'sad': 3,\n",
        "            'angry': 4,\n",
        "            'fearful': 5,\n",
        "            'disgust': 6,\n",
        "            'surprised': 7\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file = self.files[idx]\n",
        "        mfcc = np.load(os.path.join(self.mfcc_dir, file))\n",
        "        label_str = file.split(\"_\")[0]\n",
        "        label = self.label_map[label_str]\n",
        "        mfcc = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0)\n",
        "        return mfcc, label\n"
      ],
      "metadata": {
        "id": "bvZMQV8CAANg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the CNN"
      ],
      "metadata": {
        "id": "PgtNAg-FyM-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MFCCCNN(nn.Module):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super(MFCCCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(32 * 10 * 50, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "dlU_xRcoAFj7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# Paths and parameters\n",
        "mfcc_dir = \"/content/drive/MyDrive/multimodal_emotion_recognition/mfccs\"\n",
        "batch_size = 32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Dataset and loader\n",
        "dataset = MFCCDataset(mfcc_dir)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "a_p_N3syDecK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-Validate Split"
      ],
      "metadata": {
        "id": "Y7nyhOD_yhpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "val_size = len(dataset) - train_size  # 20% for validation\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoader for training and validation datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "7-8PGB4CDIO3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = MFCCCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "f7a-gPrpFNH1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):  # Number of epochs\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "    # Now validate after every epoch\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed during evaluation\n",
        "        for inputs, labels in val_dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_loss / len(val_dataloader)\n",
        "    val_epoch_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPJkwsFbAIiy",
        "outputId": "eeb5b0df-1adb-4fc2-c79e-8d3a5f68e269"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 3.2352, Accuracy: 23.96%\n",
            "Validation Loss: 1.7691, Validation Accuracy: 35.76%\n",
            "Epoch [2/20], Loss: 1.6059, Accuracy: 40.02%\n",
            "Validation Loss: 1.6184, Validation Accuracy: 39.24%\n",
            "Epoch [3/20], Loss: 1.3734, Accuracy: 48.96%\n",
            "Validation Loss: 1.4892, Validation Accuracy: 43.40%\n",
            "Epoch [4/20], Loss: 1.1259, Accuracy: 60.50%\n",
            "Validation Loss: 1.4323, Validation Accuracy: 48.61%\n",
            "Epoch [5/20], Loss: 0.9391, Accuracy: 67.01%\n",
            "Validation Loss: 1.2894, Validation Accuracy: 53.47%\n",
            "Epoch [6/20], Loss: 0.7264, Accuracy: 76.22%\n",
            "Validation Loss: 1.2770, Validation Accuracy: 53.12%\n",
            "Epoch [7/20], Loss: 0.6703, Accuracy: 77.86%\n",
            "Validation Loss: 1.2436, Validation Accuracy: 59.03%\n",
            "Epoch [8/20], Loss: 0.5034, Accuracy: 84.90%\n",
            "Validation Loss: 1.1748, Validation Accuracy: 58.68%\n",
            "Epoch [9/20], Loss: 0.4658, Accuracy: 86.11%\n",
            "Validation Loss: 1.1535, Validation Accuracy: 59.38%\n",
            "Epoch [10/20], Loss: 0.3877, Accuracy: 88.45%\n",
            "Validation Loss: 1.2845, Validation Accuracy: 57.64%\n",
            "Epoch [11/20], Loss: 0.3437, Accuracy: 90.71%\n",
            "Validation Loss: 1.1839, Validation Accuracy: 58.68%\n",
            "Epoch [12/20], Loss: 0.2377, Accuracy: 96.01%\n",
            "Validation Loss: 1.1594, Validation Accuracy: 60.07%\n",
            "Epoch [13/20], Loss: 0.2203, Accuracy: 95.92%\n",
            "Validation Loss: 1.1782, Validation Accuracy: 60.07%\n",
            "Epoch [14/20], Loss: 0.1918, Accuracy: 96.79%\n",
            "Validation Loss: 1.1445, Validation Accuracy: 61.46%\n",
            "Epoch [15/20], Loss: 0.1452, Accuracy: 98.18%\n",
            "Validation Loss: 1.1954, Validation Accuracy: 61.81%\n",
            "Epoch [16/20], Loss: 0.1318, Accuracy: 98.61%\n",
            "Validation Loss: 1.1523, Validation Accuracy: 62.50%\n",
            "Epoch [17/20], Loss: 0.1013, Accuracy: 99.57%\n",
            "Validation Loss: 1.1933, Validation Accuracy: 62.85%\n",
            "Epoch [18/20], Loss: 0.0891, Accuracy: 99.65%\n",
            "Validation Loss: 1.1934, Validation Accuracy: 62.15%\n",
            "Epoch [19/20], Loss: 0.0843, Accuracy: 99.83%\n",
            "Validation Loss: 1.1632, Validation Accuracy: 64.24%\n",
            "Epoch [20/20], Loss: 0.0748, Accuracy: 99.65%\n",
            "Validation Loss: 1.1776, Validation Accuracy: 61.81%\n"
          ]
        }
      ]
    }
  ]
}
