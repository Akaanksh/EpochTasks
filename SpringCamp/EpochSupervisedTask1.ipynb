{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Classifier"
      ],
      "metadata": {
        "id": "b2l8DlSwWgzu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-Mn4kaE_PkM"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([\n",
        "    [12.0, 1.5, 1, 'Wine'],\n",
        "    [5.0, 2.0, 0, 'Beer'],\n",
        "    [40.0, 0.0, 1, 'Whiskey'],\n",
        "    [13.5, 1.2, 1, 'Wine'],\n",
        "    [4.5, 1.8, 0, 'Beer'],\n",
        "    [38.0, 0.1, 1, 'Whiskey'],\n",
        "    [11.5, 1.7, 1, 'Wine'],\n",
        "    [5.5, 2.3, 0, 'Beer']\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "g5byeBlm_j31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n",
        "We map the class labels to integers and separate the data into features and target values.\n"
      ],
      "metadata": {
        "id": "_gxvZ-hIW333"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for row in data:\n",
        "    if row[3] == 'Wine':\n",
        "        row[3] = 0\n",
        "    elif row[3] == 'Beer':\n",
        "        row[3] = 1\n",
        "    elif row[3] == 'Whiskey':\n",
        "        row[3] = 2\n",
        "    else:\n",
        "        row[3] = None\n",
        "\n",
        "# Just for naming things nicely later\n",
        "features = ['Alcohol Content', 'Sugar', 'Color']\n",
        "classes = ['Wine', 'Beer', 'Whiskey']"
      ],
      "metadata": {
        "id": "qEftPnqq_rlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating features (X) and labels (y)\n",
        "X_train = np.array(data[:, :3], dtype = float)\n",
        "y_train = np.array(data[:, 3], dtype = int)"
      ],
      "metadata": {
        "id": "_C_lr8BSFZ5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Impurity Functions\n",
        "\n",
        "Both Gini impurity and entropy functions are implemented here.\n"
      ],
      "metadata": {
        "id": "pOQpKZS6W_O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def giniImpurity(y):\n",
        "    m = len(y)\n",
        "    if m == 0:\n",
        "        return 0  # No data, no impurity\n",
        "    counts = np.bincount(y)  # Count how many of each class\n",
        "    prob = counts / m\n",
        "    return 1 - np.sum(prob ** 2)  # Standard Gini formula"
      ],
      "metadata": {
        "id": "O2jUk8GwK29g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y):\n",
        "    m = len(y)\n",
        "    if m==0:\n",
        "        return 0\n",
        "    counts = np.bincount(y)\n",
        "    prob = counts/m\n",
        "    prob = prob[prob>0] # Remove 0 probability to avoid log0\n",
        "    return -np.sum(prob*np.log2(prob))"
      ],
      "metadata": {
        "id": "y1-SuvtlNj4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tree Node"
      ],
      "metadata": {
        "id": "ZcRv0yizXNvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "    def __init__(self, featureIndex, threshold, left, right, value):\n",
        "        self.featureIndex = featureIndex  # which feature to split on\n",
        "        self.threshold = threshold        # value to split at\n",
        "        self.left = left                  # left subtree\n",
        "        self.right = right                # right subtree\n",
        "        self.value = value                # final predicted class (if leaf)\n"
      ],
      "metadata": {
        "id": "Q36vQGbMJpJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the best split\n",
        "\n",
        "Have implemented functions to find the best split features and thresholds using both Gini impurity and entropy"
      ],
      "metadata": {
        "id": "lniJa1nYXSdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tries all possible splits and picks the one with lowest Gini impurity\n",
        "def findBestSplitGini(X, y):\n",
        "\n",
        "    numSamples, numFeatures = X.shape\n",
        "    minGiniImp = float('inf')  # start with something huge\n",
        "    bestFeature = None\n",
        "    bestThreshold = None\n",
        "\n",
        "    for i in range(numFeatures):  # for each feature\n",
        "        thresholds = np.unique(X[:, i])  # try each unique value as a split point\n",
        "        for threshold in thresholds:\n",
        "            left = X[:, i] < threshold\n",
        "            right = X[:, i] >= threshold\n",
        "\n",
        "            # weighted average of Gini impurities on both sides\n",
        "            totalGiniImp = ((len(left)/numSamples)*giniImpurity(y[left])) + ((len(right)/numSamples)*giniImpurity(y[right]))\n",
        "            if totalGiniImp < minGiniImp:\n",
        "                minGiniImp = totalGiniImp\n",
        "                bestFeature = i\n",
        "                bestThreshold = threshold\n",
        "\n",
        "    return bestFeature, bestThreshold"
      ],
      "metadata": {
        "id": "k4dRrcKa47zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as above but using Entropy in place of Gini\n",
        "def findBestSplitEntropy(X, y):\n",
        "    numSamples, numFeatures = X.shape\n",
        "    minEnt = float('inf')\n",
        "    bestFeature = None\n",
        "    bestThreshold = None\n",
        "    for i in range(numFeatures):\n",
        "        thresholds = np.array(np.unique(X[:,i]))\n",
        "        for threshold in thresholds:\n",
        "            left = np.array(X[:,i]<threshold)\n",
        "            right = np.array(X[:,i]>=threshold)\n",
        "            totalEnt = ((len(left)/numSamples)*entropy(y[left]))+((len(right)/numSamples)*entropy(y[right]))\n",
        "            if totalEnt<=minEnt:\n",
        "                minEnt = totalEnt\n",
        "                bestFeature = i\n",
        "                bestThreshold = threshold\n",
        "    return bestFeature, bestThreshold\n"
      ],
      "metadata": {
        "id": "0lbt6PbbPx3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting training data to make tree"
      ],
      "metadata": {
        "id": "8QOsagchj4Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursive function to build the decision tree\n",
        "def makeTree(X, y, maxDepth, curDepth=0, minSamples=1):\n",
        "    # Base case: if tree is deep enough, or data is pure (only one class), or no data left\n",
        "    if curDepth == maxDepth or len(np.unique(y)) == 1 or len(y) <= 0:\n",
        "        return Node(None, None, None, None, np.argmax(np.bincount(y)))  # return majority class\n",
        "\n",
        "    # Otherwise, find best feature + threshold to split on\n",
        "    bestFeature, bestThreshold = findBestSplitEntropy(X, y)\n",
        "\n",
        "    if bestFeature is None:  # just in case we can't split\n",
        "        return Node(None, None, None, None, np.argmax(np.bincount(y)))\n",
        "\n",
        "    # Actually split the data\n",
        "    left = X[:, bestFeature] < bestThreshold\n",
        "    right = X[:, bestFeature] >= bestThreshold\n",
        "\n",
        "    # Recursively build left and right subtrees\n",
        "    leftTree = makeTree(X[left], y[left], maxDepth, curDepth+1)\n",
        "    rightTree = makeTree(X[right], y[right], maxDepth, curDepth+1)\n",
        "\n",
        "    # Return node with references to the two subtrees\n",
        "    return Node(bestFeature, bestThreshold, leftTree, rightTree, None)\n"
      ],
      "metadata": {
        "id": "GonogFbvBTcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "tW8hY34ckHtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tree, x):\n",
        "    if tree.value is not None:\n",
        "        return tree.value\n",
        "    if x[tree.featureIndex] < tree.threshold:\n",
        "        return predict(tree.left, x)\n",
        "    else:\n",
        "        return predict(tree.right, x)\n",
        "\n",
        "def predictMultiple(tree, X):\n",
        "    return np.array([predict(tree, x) for x in X])"
      ],
      "metadata": {
        "id": "-SL_Lco6BT4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the tree"
      ],
      "metadata": {
        "id": "ccSg2mSpmGXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = np.array([\n",
        "    [6.0, 2.1, 0],   # Expected: Beer\n",
        "    [39.0, 0.05, 1], # Expected: Whiskey\n",
        "    [13.0, 1.3, 1]   # Expected: Wine\n",
        "])"
      ],
      "metadata": {
        "id": "5VRcgCGcMLKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build tree and make predictions\n",
        "tree = makeTree(X_train, y_train, 3, 0)\n",
        "predictions = predictMultiple(tree, test_data)\n",
        "\n",
        "# Print out the predictions in string form\n",
        "for prediction in predictions:\n",
        "    print(classes[prediction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5U6maPWMLlL",
        "outputId": "9f8867c6-86e0-4b4a-e23d-eb1f39d6777a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beer\n",
            "Whiskey\n",
            "Wine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing tree in a formatted way"
      ],
      "metadata": {
        "id": "EfD0E2reojVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursively prints tree in a formatted manner\n",
        "def printFormattedTree(node):\n",
        "    if node.value is not None:\n",
        "        print(\"the class is\", classes[node.value])\n",
        "    else:\n",
        "        print(\"if the feature\", features[node.featureIndex], \"<\", node.threshold, \": go left and\", end=\" \")\n",
        "        printFormattedTree(node.left)\n",
        "        print(\"if the feature\", features[node.featureIndex], \">=\", node.threshold, \": go right and\", end=\" \")\n",
        "        printFormattedTree(node.right)\n",
        "\n",
        "printFormattedTree(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZntMBrbU8ih",
        "outputId": "d82ede2b-8153-413c-a837-1c01c8e7e6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if the feature Color < 1.0 : go left and the class is Beer\n",
            "if the feature Color >= 1.0 : go right and if the feature Sugar < 1.2 : go left and the class is Whiskey\n",
            "if the feature Sugar >= 1.2 : go right and the class is Wine\n"
          ]
        }
      ]
    }
  ]
}
